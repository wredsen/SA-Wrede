{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import scipy.integrate as sc_integrate\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import A2C, DQN\n",
    "\n",
    "# using wredsen's symbtools fork (https://github.com/wredsen/symbtools @ DAE_statefeedback), assuming repos SA-Wrede and symbtools share the same parent directory\n",
    "sys.path.append('../../symbtools/')\n",
    "import symbtools as st\n",
    "import sympy as sp\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical system description with SymPy / symbtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1, F2 = sp.symbols('F1 F2')\n",
    "\n",
    "params = sp.symbols('m1, m2, l1, g')\n",
    "st.make_global(params)\n",
    "params_values = [(m1, 1.0), (m2, 0.1), (l1, 0.5), (g, 9.81)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model etc. from pickle of flatness analysis notebook\n",
    "with open(\"../flatness_notebooks/single_crane_model.pcl\", \"rb\") as pfile:\n",
    "    data = pickle.load(pfile)\n",
    "    locals().update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}p_{1}\\\\p_{2}\\\\q_{1}\\\\\\dot{p}_{1}\\\\\\dot{p}_{2}\\\\\\dot{q}_{1}\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[   p1],\n",
       "[   p2],\n",
       "[   q1],\n",
       "[pdot1],\n",
       "[pdot2],\n",
       "[qdot1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.xx ##:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}m_{2} \\ddot{p}_{1} - \\frac{\\tau_{2} \\left(p_{1} - q_{1}\\right)}{\\sqrt{p_{2}^{2} + \\left(p_{1} - q_{1}\\right)^{2}}}\\\\g m_{2} + m_{2} \\ddot{p}_{2} - \\frac{p_{2} \\tau_{2}}{\\sqrt{p_{2}^{2} + \\left(p_{1} - q_{1}\\right)^{2}}}\\\\m_{1} \\ddot{q}_{1} - \\tau_{1} + \\frac{\\tau_{2} \\left(p_{1} - q_{1}\\right)}{\\sqrt{p_{2}^{2} + \\left(p_{1} - q_{1}\\right)^{2}}}\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[       m2*pddot1 - tau2*(p1 - q1)/sqrt(p2**2 + (p1 - q1)**2)],\n",
       "[       g*m2 + m2*pddot2 - p2*tau2/sqrt(p2**2 + (p1 - q1)**2)],\n",
       "[m1*qddot1 - tau1 + tau2*(p1 - q1)/sqrt(p2**2 + (p1 - q1)**2)]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.calc_state_eq(force_recalculation=True)\n",
    "mod.eqns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states_dot = mod.f + mod.g * sp.Matrix([F1, F2]) ##:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_dot_wo_params = states_dot.subs(params_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_dot_func = st.expr_to_func([*mod.xx, F1, F2], states_dot_wo_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pygent utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation(x, xIsAngle):\n",
    "    obsv = []\n",
    "    for i, state in enumerate(x):\n",
    "        if xIsAngle[i]:\n",
    "            obsv.append(np.cos(state))\n",
    "            obsv.append(np.sin(state))\n",
    "        else:\n",
    "            obsv.append(state)\n",
    "\n",
    "    return np.array(obsv)\n",
    "\n",
    "def mapAngles(xIsAngle, x, mod=np):\n",
    "        \"\"\" Maps angles to the interval [-pi,pi]. \"\"\"\n",
    "        x_pi = []\n",
    "        for i, state in enumerate(x):\n",
    "            if xIsAngle[i]:\n",
    "                # map theta to [-pi,pi]\n",
    "                x_pi.append((state + mod.pi) % (2*mod.pi) - mod.pi)   \n",
    "            else:\n",
    "                x_pi.append(state)\n",
    "        return x_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "import gym\n",
    "from gym import logger, spaces\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import animation\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import FuncFormatter, MultipleLocator\n",
    "from scipy.integrate import solve_ivp\n",
    "import inspect\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "class Environment(object):\n",
    "    \"\"\" Environment base class.\n",
    "\n",
    "    Args:\n",
    "        x0 (array, list, callable):\n",
    "\n",
    "    Attributes:\n",
    "\n",
    "        x (array): current state x[k] (size = n)\n",
    "        x_ (array): previous state x[k-1](size = n)\n",
    "        history (array): previous states (x[0],x[1],...,x[k-1])\n",
    "        tt (list): time vector (corresponding to history)\n",
    "        terminated (bool): True, if environment is in a terminal state\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x0, uDim, dt):\n",
    "        if callable(x0):\n",
    "            self.x0 = x0  # initial state\n",
    "            x0 = x0()\n",
    "        else:\n",
    "            x0 = list(x0)\n",
    "            self.x0 = x0\n",
    "        self.x = x0  # current state\n",
    "        self.x_ = x0 # previous state x[k-1]\n",
    "        self.xDim = len(x0) # state dimension\n",
    "        self.oDim = self.xDim # observation dimension\n",
    "        self.uDim = uDim # inputs\n",
    "        self.xIsAngle = np.zeros([self.xDim], dtype=bool)\n",
    "        self.history = np.array([x0])\n",
    "        self.tt = [0]\n",
    "        self.terminated = False\n",
    "        self.uMax = np.ones(uDim)\n",
    "        self.dt = dt\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.x\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\" Resets environment to state x0\n",
    "\n",
    "        Args:\n",
    "            x0 (array, list, callable): initial state\n",
    "\n",
    "        \"\"\"\n",
    "        if callable(self.x0):\n",
    "            x0 = self.x0()\n",
    "        self.history = np.array([x0])\n",
    "        self.x_ = x0\n",
    "        self.x = x0\n",
    "        self.tt = [0]\n",
    "        self.terminated = False\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self, *args):\n",
    "        return\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\" Plots the environments history\n",
    "\n",
    "        Returns:\n",
    "            fig (matplotlib.pyplot.figure)\n",
    "            ax (matploltib.pyplot.axes)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        fig, ax = plt.subplots(len(self.x), 1, dpi=300, sharex=True)\n",
    "        # Plot state trajectories\n",
    "        if len(self.x) > 1:\n",
    "            for i in range(len(self.x)):\n",
    "                ax[i].step(self.tt, self.history[:, i], 'b',  lw=1)\n",
    "                ax[i].set_ylabel(r'$x_'+str(i+1)+'$')\n",
    "                ax[i].grid(True)\n",
    "                if self.xIsAngle[i]:\n",
    "                    ax[i].yaxis.set_major_formatter(FuncFormatter(\n",
    "                        lambda val, pos: '{:.0g}$\\pi$'.format(val / np.pi) if val != 0 else '0'))\n",
    "                    ax[i].yaxis.set_major_locator(MultipleLocator(base=np.pi))\n",
    "        else:\n",
    "            ax.step(self.tt, self.history[:, 0], 'b',  lw=1)\n",
    "            ax.grid(True)\n",
    "            plt.ylabel(r'$x_1$')\n",
    "        fig.align_ylabels(ax)\n",
    "        plt.xlabel(r't[s]')\n",
    "        plt.tight_layout()\n",
    "        # Todo: save data in numpy arrays\n",
    "        return fig, ax\n",
    "\n",
    "    def save_history(self, filename, path):\n",
    "        history_dict = {'tt': self.tt, 'xx': self.history}\n",
    "        pickle.dump(history_dict, open(path + filename +'.p', 'wb'))\n",
    "        pass\n",
    "\n",
    "    def animation(self):\n",
    "        pass\n",
    "\n",
    "    def observe(self, x):\n",
    "        return x\n",
    "\n",
    "class OpenAIGym(Environment):\n",
    "    \"\"\" Environment subclass, that is a wrapper for an 'OpenAI gym' environment.\n",
    "\n",
    "    Attributes:\n",
    "        ode (function): ODE for simulation\n",
    "        cost (function): ODE for simulation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, id, render=True):\n",
    "        self.env = gym.make(id)\n",
    "        x0 = self.env.reset()\n",
    "        uDim = self.env.action_space.shape[0]\n",
    "        super(OpenAIGym, self).__init__(list(x0), uDim, self.env.dt)\n",
    "        self.uMax = self.env.action_space.high[0]*np.ones(uDim)\n",
    "        self.o_ = self.x_\n",
    "        self.o = self.x\n",
    "        self.render = render\n",
    "\n",
    "    def step(self, *args):\n",
    "        \"\"\" Simulates the environment for 1 step of time t.\n",
    "\n",
    "        Args:\n",
    "            dt (int, float): duration of step (not solver step size)\n",
    "            u (list, ndarray): control/action\n",
    "\n",
    "        Returns:\n",
    "            c (float): cost of state transition\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if args.__len__()==2:\n",
    "            u = args[0]\n",
    "            dt = args[1]\n",
    "        elif args.__len__() == 1:\n",
    "            u = args[0]\n",
    "            dt = self.dt\n",
    "\n",
    "        if self.render:\n",
    "            self.env.render()\n",
    "\n",
    "        self.x_ = self.x  # shift state (x[k-1] = x[k])\n",
    "        self.o_ = self.o\n",
    "        x, r, terminate, info = self.env.step(u)\n",
    "        c = -r # cost = - reward\n",
    "        self.x = list(x)\n",
    "        self.o = self.x\n",
    "        self.history = np.concatenate((self.history, np.array([self.x])))  # save current state\n",
    "        self.tt.extend([self.tt[-1] + dt])  # increment simulation time\n",
    "        self.terminated = terminate\n",
    "        return c*dt\n",
    "\n",
    "    def reset(self, x0):\n",
    "        x0 = list(self.env.reset())\n",
    "        self.history = np.array([x0])\n",
    "        self.x_ = x0\n",
    "        self.x = x0\n",
    "        self.tt = [0]\n",
    "        self.terminated = False\n",
    "\n",
    "class StateSpaceModel(Environment):\n",
    "    \"\"\" Environment subclass that uses a state space model of the form dx/dt = f(x, u)\n",
    "    to represent the environments dynamics.\n",
    "\n",
    "    Args:\n",
    "        ode\n",
    "        cost\n",
    "        x0\n",
    "        uDim\n",
    "\n",
    "    Attributes:\n",
    "        ode (function): ODE for simulation\n",
    "        cost (function): cost function (returns scalar)\n",
    "        xIsAngle (ndarray): 'True' if state is an angle, 'False' otherwise\n",
    "        o\n",
    "        o_\n",
    "        oDim\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ode, cost, x0, uDim, dt,\n",
    "                 terminal_cost=0.):\n",
    "        super(StateSpaceModel, self).__init__(x0, uDim, dt)\n",
    "        self.ode = ode\n",
    "        params = inspect.signature(cost).parameters\n",
    "        cost_args = params.__len__()\n",
    "        if cost_args == 1:\n",
    "            self.cost = lambda x_, u_, x, t, mod: cost(x_)\n",
    "        elif cost_args == 2:\n",
    "            if 'mod' in params:\n",
    "                self.cost = lambda x_, u_, x, t, mod: cost(x_, mod)\n",
    "            elif 't' in params:\n",
    "                self.cost = lambda x_, u_, x, t, mod: cost(x_, t)\n",
    "            else:\n",
    "                self.cost = lambda x_, u_, x, t, mod: cost(x_, u_)\n",
    "        elif cost_args == 3:\n",
    "            if 'mod' in params:\n",
    "                self.cost = lambda x_, u_, x, t, mod: cost(x_, u_, mod)\n",
    "            elif 't' in params:\n",
    "                self.cost = lambda x_, u_, x, t, mod: cost(x_, u_, t)\n",
    "            else:\n",
    "                self.cost = lambda x_, u_, x, t, mod: cost(x_, u_, x)\n",
    "        elif cost_args == 4:\n",
    "            if 'mod' in params and 't' in params:\n",
    "                self.cost = lambda x_, u_, x, t, mod: cost(x_, u_, t, mod)\n",
    "            elif 'mod' in params and not 't' in params:\n",
    "                self.cost = lambda x_, u_, x, t, mod: cost(x_, u_, x, mod)\n",
    "            else:\n",
    "                self.cost = lambda x_, u_, x, t, mod: cost(x_, u_, x, t)\n",
    "        elif cost_args == 5:\n",
    "            self.cost = cost\n",
    "        else:\n",
    "            print('Cost function must to be of the form c(x_, u_, x, t, mod), where mod is numpy/sympy.')\n",
    "            assert(True)\n",
    "        self.xIsAngle = np.zeros([len(self.x_)], dtype=bool)\n",
    "        self.o = self.x\n",
    "        self.o_ = self.x_\n",
    "        self.oDim = len(self.o)  # observation dimensions\n",
    "        self.terminal_cost = terminal_cost\n",
    "\n",
    "    def step(self, *args):\n",
    "        \"\"\" Simulates the environment for 1 step of time t.\n",
    "\n",
    "        Args:\n",
    "            dt (int, float): duration of step (not solver step size)\n",
    "            u (array): control/action\n",
    "\n",
    "        Returns:\n",
    "            c (float): cost of state transition\n",
    "\n",
    "        \"\"\"\n",
    "        self.x_ = self.x  # shift state (x[k-1] = x[k])\n",
    "        self.o_ = self.o\n",
    "        if args.__len__()==2:\n",
    "            u = args[0]\n",
    "            dt = args[1]\n",
    "        elif args.__len__() == 1:\n",
    "            u = args[0]\n",
    "            dt = self.dt\n",
    "\n",
    "        # system simulation\n",
    "        sol = solve_ivp(lambda t, x: self.ode(t, x, u), (0, dt), self.x_, 'RK45')\n",
    "        # todo: only output value of the last timestep\n",
    "        y = list(sol.y[:, -1])  # extract simulation result\n",
    "        self.x = y\n",
    "        self.o = self.observe(self.x)\n",
    "        self.history = np.concatenate((self.history, np.array([self.x])))  # save current state\n",
    "        self.tt.extend([self.tt[-1] + dt])  # increment simulation time\n",
    "        self.terminated = self.terminate(self.x)\n",
    "        #x_2pi = mapAngles(self.xIsAngle, self.x_)\n",
    "        #x2pi = mapAngles(self.xIsAngle, self.x)\n",
    "        #c = (self.cost(x_2pi, u, x2pi, np) + self.terminal_cost*self.terminated)*dt\n",
    "        t = self.tt[-1]\n",
    "        c = (self.cost(self.x_, u, self.x, t, np) + self.terminal_cost * self.terminated) * dt\n",
    "        return c\n",
    "\n",
    "    def terminate(self, x):\n",
    "        \"\"\" Check if a 'terminal' state is reached.\n",
    "\n",
    "            Args:\n",
    "                x (ndarray, list): state\n",
    "\n",
    "            Returns:\n",
    "                terminated (bool): 'True' if 'x' is a terminal state. \"\"\"\n",
    "\n",
    "        terminated = False\n",
    "        return terminated\n",
    "\n",
    "\n",
    "    def fast_step(self, *args):\n",
    "        \"\"\" Simulates the environment for 1 step of time t, using Euler forward integration.\n",
    "\n",
    "        Args:\n",
    "            dt (int, float): duration of step (not solver step size)\n",
    "            u (array): control/action\n",
    "\n",
    "        Returns:\n",
    "            c (float): cost of state transition\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if args.__len__()==2:\n",
    "            u = args[0]\n",
    "            dt = args[1]\n",
    "        elif args.__len__() == 1:\n",
    "            u = args[0]\n",
    "            dt = self.dt\n",
    "\n",
    "        self.x_ = self.x  # shift state (x[k-1] := x[k])\n",
    "        self.o_ = self.o\n",
    "\n",
    "        # Euler forward step\n",
    "        y = self.x_ + dt*self.ode(None, self.x_, u)\n",
    "        self.x = y\n",
    "        self.o = self.observe(self.x)\n",
    "        self.history = np.concatenate((self.history, np.array([self.x])))  # save current state\n",
    "        self.tt.extend([self.tt[-1] + dt])  # increment simulation time\n",
    "        self.terminated = self.terminate(self.x)\n",
    "        t = self.tt[-1]\n",
    "        c = (self.cost(self.x_, u, self.x, t, np) + self.terminal_cost*self.terminated)*dt\n",
    "        return c\n",
    "\n",
    "    def observe(self, x):\n",
    "        obsv = observation(x, self.xIsAngle)\n",
    "        return obsv\n",
    "\n",
    "class Pendulum(StateSpaceModel):\n",
    "    metadata = {}\n",
    "\n",
    "    def __init__(self, cost, x0, dt):\n",
    "        super(Pendulum, self).__init__(self.ode, cost, x0, 1, dt)\n",
    "        self.xIsAngle = [True, False]\n",
    "        self.o = self.observe(self.x)\n",
    "        self.o_ = self.o\n",
    "        self.oDim = len(self.o)  # observation dimensions\n",
    "        self.uMax = 3.5*np.ones(1)\n",
    "        \n",
    "        high_obs = np.array(\n",
    "            [\n",
    "                100.0,\n",
    "                100.0\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.observation_space = spaces.Box(-high_obs, high_obs, dtype=np.float32)\n",
    "        \n",
    "        high_act = np.array(\n",
    "            [ \n",
    "                100.0\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.action_space = spaces.Box(-high_act, high_act, dtype=np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def ode(t, x, u):\n",
    "\n",
    "        g = 9.81  # gravity\n",
    "        b = 0.02  # dissipation\n",
    "        u1, = u  # torque\n",
    "        x1, x2 = x\n",
    "\n",
    "        dx1dt = x2\n",
    "        dx2dt = u1 + g*np.sin(x1) - b*x2\n",
    "\n",
    "        return np.array([dx1dt, dx2dt])\n",
    "\n",
    "    def terminate(self, x):\n",
    "        x1, x2 = x\n",
    "        if abs(x2) > 10 or abs(x1)>8*np.pi:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def animation(self):\n",
    "        # mapping from theta and s to the x,y-plane (definition of the line points, that represent the pole)\n",
    "        def pendulum_plot(l, xt):\n",
    "            x_pole_end = -l * np.sin(xt[:, 0])\n",
    "            y_pole_end = l * np.cos(xt[:, 0])\n",
    "\n",
    "            return x_pole_end, y_pole_end\n",
    "\n",
    "        # line and text\n",
    "        def animate(t):\n",
    "            thisx = [0, x_pole_end[t]]\n",
    "            thisy = [0, y_pole_end[t]]\n",
    "\n",
    "            pole.set_data(thisx, thisy)\n",
    "            time_text.set_text(time_template % self.tt[t])\n",
    "            return pole, time_text,\n",
    "\n",
    "        x_pole_end, y_pole_end  = pendulum_plot(0.5, self.history)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_aspect('equal')\n",
    "        plt.ylim((-.6, .6))\n",
    "        plt.xlim((-.6, .6))\n",
    "        plt.title('Pendulum')\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        time_template = 'time = %.1fs'\n",
    "        time_text = ax.text(0.05, 1.05, '', transform=ax.transAxes)\n",
    "        pole, = ax.plot([], [], 'b-', zorder=1, lw=3)\n",
    "        circ = patches.Circle((0, 0), 0.03, fc='b', zorder=1)\n",
    "        ax.add_artist(circ)\n",
    "        # animation using matplotlibs animation library\n",
    "        ani = animation.FuncAnimation(fig, animate, np.arange(len(self.tt)), interval=self.tt[1] * 1000,\n",
    "                                      blit=True)\n",
    "        return ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kostenfunktion, Anfangswerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the incremental cost\n",
    "def c_k(x, u):\n",
    "    x1, x2 = mapAngles([1,0], x)\n",
    "    u1, = u\n",
    "    c = x1**2 + 0.1*x2**2 + 0.05*u1**2\n",
    "    return c\n",
    "\n",
    "# define the function, that represents the initial value distribution p(x_0)\n",
    "def p_x0():\n",
    "    x0 = [np.random.uniform(0.999*np.pi, 1.001*np.pi), np.random.uniform(-0.001,0.001)]\n",
    "    return x0\n",
    "\n",
    "def ode(t, x, u):\n",
    "\n",
    "        g = 9.81  # gravity\n",
    "        b = 0.02  # dissipation\n",
    "        u1, = u  # torque\n",
    "        x1, x2 = x\n",
    "\n",
    "        dx1dt = x2\n",
    "        dx2dt = u1 + g*np.sin(x1) - b*x2\n",
    "\n",
    "        return np.array([dx1dt, dx2dt])\n",
    "\n",
    "\n",
    "t = 10 # time of an episode\n",
    "dt = 0.05 # time step-size\n",
    "learning_steps = 1e5 # define training duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym-Umgebung erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment without renderings for training\n",
    "env = Pendulum(c_k, p_x0, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "#env.step(env.action_space.sample())\n",
    "#env.observation_space\n",
    "#check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./a2c_cartpole_tensorboard/A2C_6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (1, 1)) of distribution Normal(loc: tensor([[nan]]), scale: tensor([[1.]])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan]])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/a2c/a2c.py:197\u001b[0m, in \u001b[0;36mA2C.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    186\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m     reset_num_timesteps: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    195\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA2C\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:247\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    243\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 247\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:166\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 166\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/policies.py:592\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# Evaluate the values for the given observations\u001b[39;00m\n\u001b[1;32m    591\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n\u001b[0;32m--> 592\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m actions \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[1;32m    594\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mlog_prob(actions)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/policies.py:607\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    604\u001b[0m mean_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_net(latent_pi)\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[0;32m--> 607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(action_logits\u001b[38;5;241m=\u001b[39mmean_actions)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/distributions.py:153\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m action_std \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mones_like(mean_actions) \u001b[38;5;241m*\u001b[39m log_std\u001b[38;5;241m.\u001b[39mexp()\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/normal.py:54\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNormal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/distribution.py:55\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 55\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28msuper\u001b[39m(Distribution, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter loc (Tensor of shape (1, 1)) of distribution Normal(loc: tensor([[nan]]), scale: tensor([[1.]])) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan]])"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Learning!\n",
    "model = A2C('MlpPolicy', env, verbose=1, tensorboard_log=\"./a2c_cartpole_tensorboard/\")\n",
    "model.learn(total_timesteps=learning_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model with rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM default\n"
     ]
    }
   ],
   "source": [
    "obs = env_rendering.reset()\n",
    "for i in range(1000):\n",
    "    action, _state = model.predict(obs, deterministic=False)\n",
    "    obs, reward, done, info = env_rendering.step(action)\n",
    "    env_rendering.render()\n",
    "    if done:\n",
    "      obs = env_rendering.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "env_rendering.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "795px",
    "left": "1545px",
    "right": "20px",
    "top": "125px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
